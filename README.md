## Explainable AI

![License](https://img.shields.io/badge/License-MIT-green)

---

### About This Repository

This repository is a collection of all the Explainable AI programming work I completed in my college journey.


This repository contains all the code I've written, along with some reference code from other sources. Feel free to use or modify it — it's all available under the MIT License.

### Directory Structure

```
Explainable AI/
├── 01. Case study on ML models performance.ipynb
├── 01. Imbalanced Dataset - SMOTE.ipynb
├── 02. EDA on Text & Image & Tabular Data.ipynb
├── 03. Partial Dependence Plot (PDP).ipynb
├── 03. Saliency Maps & LRP.ipynb
├── 04. Feature Importance.ipynb
├── 04. Sensitivity Analysis.ipynb
├── 06. LIME For Image.ipynb
├── 06. LIME For Tabular.ipynb
├── 06. LIME For Text.ipynb
├── 07. SHAP on DL Models (Image).ipynb
├── 07. SHAP on ML Models (Tabular).ipynb
├── 07. SHAP on ML Models (Text).ipynb
├── 09. TCAV (Image).ipynb
├── 09. TCAV (text).ipynb
├── data/
├── Ouestions/
├── .gitignore
├── LICENSE.txt
└── README.md
```

### Techniques Explored

- Model interpretability using LIME and SHAP for tabular, text, and image data  
- Visual explanation techniques like saliency maps and Layer-wise Relevance Propagation  
- Feature sensitivity analysis and partial dependence plotting  
- Concept-based explanations using TCAV for deep learning models  
- Handling data imbalance with SMOTE  
- Comparative model performance analysis across various data types  
 


### License

This project is licensed under the [MIT License](LICENSE.txt).

---

### Acknowledgments

Thanks to all the professors, mentors, and peers who contributed to this learning journey. Each piece of code here tells a part of my growth as a developer.

---